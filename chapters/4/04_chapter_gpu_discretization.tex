\startchapter{GPU discretization}
\label{chapter:GPUDiscretization}
In the previous chapter we presented an algorithm for polygonization of the \blob scene graphs on 
multi-core architectures. The output of that algorithm is a list of vertices with their associated attributes 
such as position, color and normal and a list of triangles that defines the connectivity of the surface mesh. 
While the surface mesh is used for rasterization it can also facilitate collision detection and contact 
modelling algorithms as we will see in the following chapters.  In this chapter we present an improved 
version of that algorithm that can take advantage of the processing capabilities of the GPU and provides 
scalable rendering performance on many-core architectures. 


Building on top of the results from our SIMD polygonization algorithm, in this chapter we present our 
work in optimizing that algorithm for many-core architectures such as GPU. The following are some of 
the reasons behind this effort:

\begin{enumerate}
 \item The polygonization process extracts a triangle mesh which ultimately requires rasterization for 
 rendering. Using a GPU implementation both steps can be fused together thus avoiding the expensive 
 read-backs. 

 \item GPUs provide a higher degree of SIMD processing which is also called SIMT for single instruction
 multiple threads. Using the same strategy, multiple units execute the same 
 fetched and decoded instruction; however, on the GPU side there is a wider access to 
 register sets, multiple flow paths and access to multiple memory addresses that can scale the 
 performance of each running thread significantly. 
  
 \item Using flexible and portable OpenCL programming, the polygonization code can be written 
 in simple, scalar arithmetic and the runtime environment will handle multi-threaded task 
 parallelism and vector width SIMD processing on the target hardware. This 
 is certainly much more readable and extensible code than using non-portable, machine 
 intrinsic functions for SIMD processing.
 
 
\end{enumerate}


When compared to the related work in the field, our proposed method has the following benefits:

\begin{itemize}
 \item It is dynamic, i.e., the input to our algorithm is a dynamic \blob structure that can change 
 in every frame. This is a key advantage that can enable interactive modelling sessions in an implicit 
 framework, i.e. the result of modifications to the model can be viewed in real-time. 
 After each change the associated meshes are updated dynamically. 

 \item It is high performance. The proposed GPU-based data-structure is compact enough to enable 
 rendering complex \blob models in the order of 60,000 nodes. (64,000 nodes only requires about 
 20MiB of video memory in our system).
\end{itemize}


The next section provides an overview on the design differences between a CPU and 
a GPU. Other considerations for memory and access patterns are discussed in that section.  
Next the data-structure and the new algorithm are explained. The chapter concludes with the results 
and analysis.

%Another requirement for the tetrahedral mesh generation is that the triangular surface mesh should be the boundary surface of the tetrahedral mesh. This is needed since 
%after applying the displacements to the volumetric tetrahedral elements the surface vertices should be displaced as well.
\section{Many-cores architectures}
One of the main differences between a multi-core CPU versus a many-core GPU 
architecture is the fact that the former is optimized for the fast execution of 
a single task by supporting a broad-set of instructions in hardware, where as the latter can accommodate 
heavy parallel processing in the format of single instruction multiple data (SIMD). 

CPU designers incorporate complex multi-cycle pipeline methodologies to amortize 
the amount of computation in a single machine cycle, e.g. by overlapping the execution of independent 
instructions at different cores, all cores of a processor are kept busy working on a different instruction. 
GPU designs take a different approach to parallelism. They achieve higher SIMD throughput by assigning 
more of the chip area to arithmetic logic units (ALUs) and less to fancy branch predictions and flow control. 
GPUs also have access to higher memory bandwidth when compared to their CPU counterparts.


The advent of programmable graphics pipeline opened up new avenues to exploit computational resources of the
GPU hardware. Before the introduction of general-purpose GPU (GPGPU) programming languages, such as open compute language (OpenCL), 
researchers in the field were forced to use computer graphics shading languages (e.g. glsl, cg) to gain access to 
the many-core architecture of GPUs. 

Many of the terms associated with solving rendering issues were borrowed to explain solutions to problems in 
other domains of science. Terms such as vertex, fragment and texture which define entities in a graphics 
shading problem were used to refer to the processing threads, work items and the input for a solution to a 
problem in high performance computing domain. In addition to the lack of a general language for computing on the GPUs, 
the complexity of mapping the problem domain to the graphics pipeline complicated the implementations and lead 
to various ad-hoc solutions to the same problems. For instance, Georgii \etal created an interactive cloth simulation 
by implementing a mass-spring system using fragment shader programming on an ATI X800 graphics card \cite{Georgii2005}. 
As another example S{\o}rensen \etal reviewed several shader programming techniques for accelerating 
linear system solving on GPUs with applications in surgical simulation \cite{SÃ¸rensen2006a}. 

At the time of this writing, the following languages are commonly used for GPGPU computing:
\begin{itemize}
 \item Nvidia CUDA (Compute Unified Device Architecture)
 \item Microsoft's DirectCompute
 \item OpenCL which is a standard language maintained by Khronos Group
\end{itemize}

Among all, OpenCL is the only language that is designed to be platform and 
host operating system independant, DirectCompute supports all hardware vendors
but is limited to Windows and CUDA is only available on Nvidia's hardware. 

OpenCL and CUDA share similar concepts in their programming model \cite{gaster2012heterogeneous}.
One of the major drawbacks of OpenCL when compared to CUDA is the initialization delay 
associated with the kernel compile process at runtime. The delay is significant for long
and complex kernels and at the time of this writing, no offline compiler is offered by Nvidia
to alleviate this issue. One way to improve this is to compile and store the binaries 
on disk upon the first kernel invocation and reuse the precompiled binaries for subsequent 
executions. 

The other technical issue that we faced with OpenCL is that the performance optimizations 
made on one platform are not transferred to other platforms. This situation has been experienced
by other researchers in the field and essentially there is no guaranteed portability for the 
tuning and optimizations of the kernels.
The algorithms that are presented in this chapter are implemented using OpenCL. 

OpenCL and CUDA use similar memory model to execute kernels on the GPU. Each thread of 
execution on the GPU has access to a limited amount of local memory that is private to that thread. 
The local memory for the thread is used to store the stack frames. It is also used in register spilling, 
which occurs when the local and private variables of the thread can not fit into the register file of the
physical core and they spill to the local memory. Each thread belongs to a thread block. In OpenCL terms 
a thread is referred to as a processing element and a thread block is called a compute unit. 

All processing elements within a compute unit has access to a shared memory block, which is 
accessible by all processing elements within the same block. Beside the local and shared memory
spaces, all processing elements have access to a global memory block which has the slowest access 
time when compared to the other two spaces. 

Physically, the local and shared memory spaces can be seen as level 1 and level 2 cache memory on the 
CPU and the global memory as the main memory (i.e. video memory on the GPU).



\section{Data Structures}
\label{sec:datastructure}
The \blob linearization step introduced in (section \ref{sec:linearization}) is modified to create a compact 
representation of the input model in our GPU polygonization algorithm. 

All the structures are aligned at 16 bytes (four floating points) memory addresses. This is similar to the texture 
accessing techniques in graphical shader programming languages such as GLSL or Cg, where four floats represent the 
RGBA values of a texel accordingly. If a primitive node has an associated transformation node with a non-identity 
transformation matrix, that matrix will be stored in the primitive matrices section of the input structure and an 
associated identifier (id) will be provided to the primitive. The inverse of the primitive matrix is computed 
and the first three rows are stored for further field computations. To transform the axis-aligned bounding 
boxes of the primitives, the full forward transformation matrix is stored in the box matrices section of 
the structure and it can be accessed using the same id provided for the primitive matrix.
Figure (\ref{fig:datastructure}) depicts this pointerless representation in details.

\begin{figure}[H]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/gpupoly/lineartree.pdf}
  \caption{\label{fig:datastructure}
  {The compact \blob scenegraph representation for GPU polygonization and tetrahedralization algorithms. The structure is 
  aligned at 16 bytes (4 floats). 1- The header. 2- Skeletal implicit primitives. 3- Operators. 4- Affine transformation 
  nodes. 5- Control points for sketched objects. Refer to section \ref{sec:datastructure} for details.}
}
\end{figure}

Each input data-structure is numbered in figure (\ref{fig:datastructure}) for further reference. We review the details in the following:
\begin{enumerate}
 \item The header section defines the lower and upper corner of the axis-aligned bounding box enclosing the entire model, 
 i.e. the convex hull of the input \blob. The header also contains the count of primitives, operators and the transformation 
 nodes. The id associated with the root operator of the tree is also defined in the header.
 
 \item The definition of each primitive is encoded in 6 texels. The $TP$ field in the first texel numerically encodes the 
 type of skeletal primitive. The other three fields in this texel are $MX$, $PR$ and $SB$ that link this primitive to its inverse 
 transformation matrix, the parent and the sibling elements respectively. The following texels define the position, 
 direction, skeleton-specific parameters and the color of the primitive. For the primitives that are 
 computed from sketched control points (e.g. the thin-plate spline primitives \cite{Turk1999, Grasberger}) the indices to the 
 associated first and last control points are stored in the last texel.

 \item A \blob operator is defined in 4 texels. Similar to the structure shown 
 in figure \ref{fig:linearized_blobtree}, links are provided to the child nodes.  
 Other fields added to support our stackless \blob traversal algorithm which is explained in the following 
 sections. The $NX$ field defines the next operator node in the \blob traversal route. 
 The $F^*$ field contains the flag bits that provide more control over the operator and the definition of 
 each can be found at the bottom of figure \ref{fig:datastructure}. Bits 1 and 0 are set in case the left child 
 or the right child of the current node are operators as well. Bit 2 is 
 set if the $LC$ and $RC$ indices are actually defining a range of indices for primitive children. If the unary 
 flag is set then the operator has only one child which is stored in the $LC$ field.  
 Bit 4 is set when the current operator appears as a right node for its parent. Bit 5 is the break route flag and is discussed further 
 in our stackless \blob routing algorithm. The rest of the bits are reserved for future use. 
 
 
 \item As mentioned above the inverse of the transformation matrices are computed and the first three rows are stored in our input 
 structure for field computation purposes. The elements are depicted in the format of [row][column]. The forward transformation is 
 stored as a 4x4 matrix in a separate input structure for performance reasons. 
 
 \item The control points associated with the sketched primitives are all stored in this section. Each control point is defined with 
 their XYZ coordinate and an associated weight value. 
\end{enumerate}

\section{Memory foot prints}\label{sec:memory}
After analyzing the performance of our OpenCL kernels, register spilling often found to be the major 
cause for many latencies. Resorting to shared memory spaces, reducing number of intermediate variables 
in field-evaluation kernels and avoiding loop unrolling in some cases helped to optimize the performance. 
Upon every change in the input \blob the linearized \blob is updated and transferred from main memory 
to the GPU. Currently the maximum number of nodes is set at 64K which covers all of the complex cases 
we modelled for this thesis. However, for larger \blob models we can easily increase this amount to 
support them. The memory footprint of our current \blob representation is summarized in table 
\ref{table:memfootprint}. Each row in the table represents a \blob with a specific number of nodes.
Starting from the simplest \blob with only one node (e.g. a sphere primitive) to the most complex \blob 
with one million nodes. The middle columns in the table are the break down of the required memory 
size per each component in the compacted \blob data structure.

\begin{table}[H]
\begin{center}
	 \caption{\label{table:memfootprint}
  {Memory footprint of the input \blob in our GPU polygonization algorithm in bytes. The entire \blob for a model with 64K nodes (primitives and operators) 
  takes up about 20 MiB in our current system.}
}
  \begin{tabular}{ | c | c | c | c | c | c | c | c |}
    \hline    
    Nodes & Header & Primitives & Operators & Prim Mtx & Box Mtx & Ctrl Points & Total \\ \hline \hline
    1 & 48 & 96/Prim & 64/Op & 48/Prim & 64/Prim & 16/Point & 320 \\ \hline
    1K & 48K & 96K & 64K & 48K & 64K & 16K & 320K \\ \hline
    64K & 3072K & 6144K & 4096K & 3072K & 4096K & 1024K & 20M \\ \hline
    1M & 48M & 96M & 64M & 48M & 64M & 16M & 320M \\ 
    \hline
  	\end{tabular}
\end{center}
\end{table}


\section{Stackless \blob traversal}
\label{sec:stackless}
As shown in figure \ref{fig:TowerSNBTimeBreakDown} the major bottleneck of the algorithm presented in chapter 
\ref{chapter:cpuPoly} is the surface extraction process. The expensive operations in that 
stage is the computation of normals and colors which require extra field evaluations and hence performance degradation. 

In this section we describe our novel stackless \blob traversal algorithm. 
Without a stack to be maintained the \blob traversal incurs less memory footprint. When dealing with small 
local memory available per thread on the GPU this reduction in memory usage improves the performance of the 
running kernels significantly. The idea behind the stackless traversal is to pre-compute a serial route to 
visit and evaluate all the operator nodes in the tree without using a global temporary storage to keep 
track of the visited nodes. An index based data structure is designed to provide sibling node access 
as well as two-way parent child relationships. This type of links help to perform horizontal and 
vertical moves in the tree structure.


In high performance rendering algorithms the use of hierarchical spatial data structures for acceleration reasons 
is common. Visiting nodes in such structures requires a stack-based depth-first search (DFS) traversal algorithm. 
Unfortunately, even the latest GPU architectures are poorly suited for implementing such algorithms. 

A complex \blob scene-graph data structure may contain thousands of primitives and operators which 
can lead to deep tree structures. Using the original DFS algorithm, the fieldvalue evaluation 
process has two stages: A ``down traversal'' followed by an ``up traversal''. 

During the down traversal stage all operators starting from the root node are visited and pushed onto an 
operators stack until a leaf node (primitive) is reached at which point the field due to the primitive is 
computed and pushed onto a separate fields stack and the next stage which is the up traversal begins.

During the up traversal stage the operators are popped out of the stack and per each child an associated field is popped from the fields stack for the 
operator to combine them in its own specific way. The resulting field is again pushed back on the fields stack.  This process continues until the 
operators stack get emptied and the final fieldvalue due to the root node is computed and returned.

Performing many push and pop operations limit the performance of the traversal process. The other issue 
relates to the inherently dynamic storage requirement for the stack itself. Although, creating a fixed-size 
stack is possible but since the stack size is a function of the number of nodes in the input, this will 
ultimately limit the maximum number of nodes in a complex scene. If $N$ is the maximum number of nodes 
(primitives plus operators) allowed in a \blob model then the minimum number of elements to be stored 
in the stack during the traversal process is equivalent to the depth of the tree. Implementing a stack in the 
global video memory will require very expensive memory transfers and is not an option for a real-time 
rendering algorithm. 

Our algorithm is based on the neighbor cell-links concept in the stackless traversal of spatial subdivision trees 
which is first introduced by Samet \etal \cite{Samet1984,Samet1990}. Using a similar technique Popov \etal presented 
a stackless KD-Tree traversal for high performance GPU ray tracing algorithm \cite{Popov2007}. 

The novelty of our technique is in the route computation and evaluation process which is completely 
different than what is proposed in Samet's and Popov's work. In our system, the geometry is not explicitly 
defined in the input structure at the time of route computation. Both Samet's and Popov's algorithms are 
based on spatial data-structures that provide explicit access to the geometry and therefore it is possible 
to recompute the missing sibling and parent-child relationships if they are not pre-computed. The 
second difference is the fact that not all the child nodes in  accelerator structures such as KD-Trees or 
BSP-trees need to be visited to answer an inclusion query, but in case of a \blob structure all nodes are 
visited in order to compute the final field due at a point in space. Once the field is computed then it is 
trivial to answer the inclusion query. A third difference is in the order of evaluating the operator nodes. 
Some operations such as difference, are not commutative and need a specific handling when computing 
the route. Such differences require special handling that clearly show the need for a different tree 
traversal algorithm.


The algorithm is divided into two stages. A preprocessing stage to compute a traversal route for the entire 
\blob and the GPU-based stackless traversal stage to compute the field-value due to a given point in space. 
The following will describe these two stages in greater details.


\begin{figure}[H]
  \centering
  % the following command controls the width of the embedded PS file
  % (relative to the width of the current column)
  \includegraphics[width=1.0\linewidth]{figures/gpupoly/stackless.pdf}
  \caption{\label{fig:stackless}
  {Stackless \blob traversal algorithm performs faster on deep tree traversals. The route is computed once and encoded into the tree upon transferring the input 
  data structures to the GPU.}
}
\end{figure}

\subsubsection{Encoding traversal route}
The first stage in our algorithm is to compute a route to visit all nodes in the \blob 
and finally encode that route in the GPU input data-structure. This process is performed only once and is not a 
bottleneck in the system. The one-time fixed cost paid for this stage on the CPU is regained 
when many fieldvalue evaluations are performed in parallel on the GPU without the extra cost 
associated with the stack storage.

To compute the route the following steps are performed on the CPU side as a preprocessing stage: 

Using the naive \blob traversal algorithm the nodes are visited from root to leaves. Two stacks are maintained in this process, an
operators stack $S1$ and a \text{break} nodes stack $S2$. The latter is defined in the following:

\begin{enumerate}
 \item If one of the children is an operator $A$ and the other is a primitive $B$. The parent for $A$ is set 
 to the current node and then it is pushed onto $S1$.
 
 \item If both children are operators. The right child is set as a \textit{break} node and is pushed on to $S2$. 
 The route at break nodes is flipped to the left branch of the tree, see figure \ref{fig:stackless}. 
 
 \item If the two children are both primitives: First the root of the \blob is set to the current node if it has not been set before.
  (Refer to the \blob header format in figure \ref{fig:datastructure} for the location of the root field shown as $RT$.) 
  A rope is created between the two primitives, linking the two nodes and a break node $B$ is popped from $S2$. 
  The next node for $B$ is set to the current node.
 
  
 \item This process is continued until $S1$ is emptied.
\end{enumerate}


%add an algorithm listing for this

%describe what happens on the GPU as well

\subsubsection{Up-sweep traversal on the GPU}
Figure \ref{fig:stackless}, shows the final route for a sample \blob. The benefits of this type of routing encoded into the tree
is that there is no need for storing a deep stack for the intermediate operators. Using this new approach the tree is now only evaluated 
from bottom to top. 

The \blob root node $RT$ marks the starting point of the traversal. This field is stored in the header section of the 
data structure as illustrated in figure \ref{fig:datastructure}. Using the new traversal route this field is set to
the operator node 10 for the example \blob shown in figure \ref{fig:stackless}. 

In case of an operator where all its children are primitives, the field due to each child is computed before the operator evaluation. 
The computed field is stored in the global field variable $F1$ and using the link to the next node provided in the structure ($NX$) 
the evaluation continues to the next operator in the tree at an upper level (up-sweep). When evaluating an operator with one primitive
child then the field due to the primitive child is computed before applying the current operator to $F1$ and performing the up-sweep (nodes 5 to 9 in 
figure \ref{fig:stackless}).

When visiting a break node the field is computed as usual but this time it is stored in the special variable $F2$, instead. 
In addition at a break node, the $NX$ field in the structure points to a non-parent operator (operator 4 for break node 3 in the example).

The process continues until the first node in the tree is evaluated at which the $F1$ and $F2$ values store the children fields for 
their parent. The $NX$ field associated with the first node points to itself which marks the end of the traversal process.


\section{GPU Surface Extraction Algorithm}
\label{sec:surfextraction}
In this section we present our GPU polygonization algorithm which is based on our novel field value evaluation technique described
in the previous section. Since the following steps are implemented using OpenCL on the GPU we will use the term \textit{kernel} which 
is a single thread of execution on the GPU. Please refer to section \ref{sec:memory} for a description of the memory model for
general purpose GPU (\textit{GPGPU}) programming.

We start by computing the axis-aligned bounding box of the model by traversing the tree from root to leaves 
and applying the transformation matrices at leaf nodes (primitives). Using the \textit{cellsize} parameter supplied by the user the 
bounding box is subdivided into a grid of voxels. The kernel \textit{ComputeAllFields} then computes a fieldvalue per each
vertex of the voxel grid and stores that value in the format of \textit{XYZF} where \text{XYZ} denotes the position and 
\textit{F} is the so-called field at that point. 


After computing all the fields, the grid edges are processed in the following order. 
Each vertex in the grid is connected to at most 6 other directly adjacent vertices. Starting from the lower corner of the voxel grid 
the kernel \textit{ProcessEdges} visits the corresponding vertex in the grid and examines only the edges that start 
from that vertex and extend to the adjacent vertices in the next index step. This way all edges in the voxel grid are checked 
and redundant traversals can be avoided. Needless to say that at boundary vertices the kernel may process less than 3 edges per each 
vertex (i.e. the ones that are within the convex-hull of the model). Upon each kernel run at this stage the index address to 
the corresponding vertex and its 3 other adjacent vertices is computed as shown in the algorithm \ref{alg:processedgeskernel}. Per each vertex
an inclusion query is performed (i.e. The fieldvalue at that vertex is compared against the iso-value. If it is greater than or equal 
the isovalue the vertex is considered inside otherwise outside the model). Two values are stored before completion of this kernel call. 
The first is the count of crossed edges at that vertex and the second one is a 3 bits flag which basically locates the intersected 
edges along x, y or z axes.


\begin{algorithm}[H]
\caption{\textit{ProcessEdges} kernel counts the number of intersected edges and their corresponding axes. 
This kernel runs per each vertex in the voxel grid.}
\label{alg:processedgeskernel}
\begin{algorithmic}[1]	
  \STATE $v = queryVertexInclusion(i, j, k)$
  \STATE $vx = queryVertexInclusion(i+1, j, k)$
  \STATE $vy = queryVertexInclusion(i, j+1, k)$
  \STATE $vz = queryVertexInclusion(i, j, k+1)$
  \STATE $count = (v \xor vx) + (v \xor vy) + (v \xor vz)$
  \STATE $flag = (((v \xor vx) << 2) or ((v \xor vy) << 1) or (v \xor vz))$
\end{algorithmic}
\end{algorithm}

In the above algorithm the \textit{queryVertexInclusion} function checks whether the vertex at a specified
voxel grid index is inside the model i.e. the field value at that vertex is greater than or equal to the \textit{isovalue}.
Then it performs the same test for the end-points of the edges emanating from the current vertex along the primary axes.
If both endpoints of an edges are inside (or outside) the model then there is no intersection between the iso-surface and
the voxel grid. Variable $count$ stores the number of intersections associated with the current vertex at the grid address 
$\left(i, j, k\right)$. In addition a 3 bits \textit{flag} variable holds the state of the intersections along the primary 
edges in the format of $XYZ$.

After processing all edges, the array \textit{EdgeBuffer} contains the count of intersected edges per each vertex 
in the voxel grid. In order to compute the total number of output vertices in the triangle mesh the prefix-sum 
\cite{Sengupta2007} of \textit{EdgeBuffer} is computed and stored in a separate gpu memory buffer called 
\textit{ScannedEdges}. The total number of vertices is the sum of the last elements in the \textit{EdgeBuffer} 
and \text{ScannedEdges} arrays. Before computing the vertex attributes such as the position, color and normal, the associated 
memory buffers are allocated on the device using the total number of vertices computed in the previous step. 

After this stage the vertex attributes of the mesh can be computed by executing a root finding method on the intersected 
edges and storing the output vertices in their appropriate buffer locations using the offsets in \textit{ScannedEdges}.
We use a Newton-Raphson root finding method which converges to the iso-surface using the gradient of the field \cite{Matthews1987}.
At each iteration the root is displaced closer to the surface according to the method given by Overveld \etal (\cite{VanOverveld2004}):

\begin{equation}
 r = r + \frac{\left(iso - f(r)\right)}{\nabla V(r).\nabla V(r)}
\end{equation}

Where $r$ is the root, $f(r)$ is the field at $r$ and $\nabla V(r)$ is the gradient of the field at $r$.
A maximum of four iterations was sufficient to provide smooth results in our tests. 
After computing the root position other attributes such as the color and normal at that vertex are also computed and stored in their 
designated buffers. The next step is to process the cells in the voxel grid in parallel and compute a configuration index per each cell
for extracting the topology of the triangles. There is no \blob traversal at this stage since the computed fields will be provided
to the kernel function. The configuration table is supplied as a texture and can be accessed using sampler unit for 
fast access. The number of triangles that are output per each cell is stored in a buffer called \textit{FaceBuffer}.

In order to find the total number of triangle elements, a prefix-sum scan is applied to the \textit{FaceBuffer} array 
in the same way that total number of vertices is computed previously. The buffer \textit{ScannedFaces} will be used to hold the 
offset values per each cell. 

The final stage in our GPU polygonizer is producing the triangles. For this purpose the kernel function \textit{GenerateFaces} 
is called per each cell in the voxel grid. No \blob traversal is required for this stage. Only the cells which intersect with the 
iso-surface are processed. Upon each kernel run the indices for the eight vertices of the current cell are computed. 

To process cell configurations we used the improved marching cubes table by Dietrich \etal 
\cite{Dietrich2009}, which avoids most of the small and badly shaped triangles. The table is supplied to the kernel as 
a texture of size 256 rows by 16 columns. To access the entries in the table the texture sampler on the hardware 
can be used. Per each cell the configuration index is computed using the previously stored fields. Each entry in the table is the 
index of an edge in the cell (There are 12 edges per each cell). Algorithm \ref{alg:generatefaceskernel} shows how the 
triangle elements are computed in this stage.

\begin{algorithm}[H]
\caption{\textit{GenerateFaces} kernel function computes the triangle indices per each cell and outputs them directly into an
OpenGL index buffer for rasterization. All the buffers can be read back from the GPU and stored.}
\label{alg:generatefaceskernel}
\begin{algorithmic}[1]	 
  \STATE $index = globalCellIndex(i, j, k, dim)$
  \STATE $config = cellconfig(i, j, k)$
  	  \IF{$config == 0$ or $config == 255 $}
	  \STATE return;
	  \ENDIF	
   \STATE $cellcorners = cellCornerIndices(i, j, k, dim)$
   \STATE $offset = ScannedFaces[index]$
   \STATE $count = FaceBuffer[index]$
   \FOR{$i=1 \to $count}
	 \STATE $edge = sample($configtable$, int2(edge, index))$
	 \STATE $start = EdgeStartIndex[edge]$
	 \STATE $axis = EdgeAxis[edge]$
	 \STATE $elements[offset + i] = ScannedEdges[cellcorners[start]] + axis$
   \ENDFOR				

\end{algorithmic}
\end{algorithm}


Upto five triangles can be extracted from each cell. Lines 11 and 12 in the algorithm assign the start index of an 
edge and its associated axis using two constant buffers supplied to the kernel for this purpose. 
The element entry is computed as an index to the global vertex buffer. The \textit{ScannedEdges} 
buffer holds the global offset for all the intersected edges as previously discussed. 

\section{Analysis and Results}
In this section we review the effects of the previous optimizations on the overall performance of the system.
In our experiments we tested the effect of the stackless \blob traversal algorithm using a set of models created 
with our incremental modelling system. To make a fair comparison the same algorithm implemented on the GPU using
the OpenCL framework once with the stack and the other time with the stackless method presented in section 
\ref{sec:stackless}. The results are shown in the following table:



\begin{table}[H]
\begin{center}
	 \caption{\label{table:stackless}
  {Stackless \blob traversal improved the performance of our \blob field evaluation significantly.
  Here is the comparison between our novel stackless approach versus the stack-based implementation for various models. 
  Timings are the average of 100 runs.}
}
  \begin{tabular}{ | c | c | c | c | c | c |}
    \hline    
    Model Name & Field Queries & Grid & Stack-based (ms) & Stack-less (ms) & Speedup \\ \hline \hline
    Tumor & 16240 & 29*20*28 & 21 & 0.8 & 26x\\ \hline
    cake & 18975 & 33*23*25 & 17 & 1 & 17x\\ \hline
    3slabs & 28750 & 46*25*25 & 30 & 2 & 15x \\ \hline
    \hline
  \end{tabular}
\end{center}
\end{table}


\begin{figure}[H]
  \centering
  % the following command controls the width of the embedded PS file
  % (relative to the width of the current column)
  \includegraphics[width=1.0\linewidth]{figures/gpupoly/combined_models.png}
  \caption{\label{fig:combinedmodels}
  {Sample models for testing our GPU polygonization method. From left to right: Cake, tumor and 3slabs.}
}
\end{figure}

When using stacks, the register spilling phenomenon mentioned previously degrades the performance due to the higher cost of accessing 
the shared memory. Conditional push and pops in the stack-based method also stalls the performance of the kernels.  

Faster field evaluations using the stackless algorithm also improves the performance of our root-finding method and the overall
polygonization time. In the following we review per kernel time break-time which provides a close look at hotspots (most time-consuming 
locations) in our implementation. 

%Tumor: Fields: 2, Edge: 1, EdgeBufferScan: 22, Vertex: 44, Cell: 1, FaceBufferScan: 18, Faces: 17, Total: 105
%Cake: Fields: 1, Edge: 1, EdgeBufferScan: 19, Vertex: 58, Cell: 2, FaceBufferScan: 17, Faces: 10, Total: 108
%3Slabs: Fields: 1, Edge: 1, EdgeBufferScan: 18, Vertex: 40, Cell: 1, FaceBufferScan: 17, Faces: 1, Total: 79

\begin{figure}[H]
  \centering
  % the following command controls the width of the embedded PS file
  % (relative to the width of the current column)
  \includegraphics[width=0.8\linewidth]{figures/gpupoly/breakdownpoly.pdf}
  \caption{\label{fig:breakdownpoly}
  {Polygonization time breakdown in milliseconds for the three models shown in the previous section. Vertex processing is the most compute-intensive
  stage due to the Newthon-Raphson root finding method employed and the evaluation of colors and normals which require additional traversals.
  }
}
\end{figure}

As it can be seen computing vertices is still the most time-consuming stage due to the extra tree traversals required for high quality 
gradiant-based Newthon-Raphson root-finding method. Computing other attributes such as colors and normals would also need 1 and 4 
traversals respectively. The prefix-sum scan operator employed here uses multi-pass computing. The extra cost of kernel calls has
increased the cost of using these operators. Several optimizations can be performed to benefit the overall performance. By 
vectorizing all kernels the core SIMD units can be used more efficiently. The prefix-sum scan operator can also be implemented in such a way 
that the memory-bank conflicts are completely avoided and the data-accesses are performed in parallel.






















